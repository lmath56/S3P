# Service
apiVersion: v1
kind: Service
metadata:
  name: ai-service
spec:
  selector:
    app: ai-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
  type: LoadBalancer

---
# Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-workload
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ai-app
  template:
    metadata:
      labels:
        app: ai-app
    spec:
      containers:
      - name: ai-container
        image: reduced
        imagePullPolicy: Never # If this is not here K8s will try and pull the container from a registry
        resources:
          limits:
            cpu: 1000m
            memory: 10000Mi
            nvidia.com/gpu: 1
          requests:
            cpu: 2000m
            memory: 4096Mi
            nvidia.com/gpu: 1
        ports:
        - containerPort: 5000
        volumeMounts:
        - name: local-storage 
          mountPath: /app/models
      volumes:
      - name: local-storage
        hostPath:
          path: /models
          type: DirectoryOrCreate